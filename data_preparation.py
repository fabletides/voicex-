#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö Vibravox –¥–ª—è –æ–±—É—á–µ–Ω–∏—è VoiceX
–ó–∞–≥—Ä—É–∑–∫–∞, –æ—á–∏—Å—Ç–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
"""

import os
import shutil
import requests
import zipfile
from pathlib import Path
import pandas as pd
import numpy as np
import librosa
import soundfile as sf
from tqdm import tqdm
import argparse

class VibravoxDataPreparator:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö Vibravox"""
    
    def __init__(self, output_dir='./vibravox_data'):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
    def download_vibravox_dataset(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ Vibravox —Å GitHub"""
        print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ Vibravox...")
        
        # URL —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
        repo_url = "https://github.com/jhauret/vibravox"
        dataset_urls = {
            'speech': 'https://github.com/jhauret/vibravox/raw/main/data/speech.zip',
            'throat': 'https://github.com/jhauret/vibravox/raw/main/data/throat_microphone.zip',
            'metadata': 'https://github.com/jhauret/vibravox/raw/main/metadata.csv'
        }
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        (self.output_dir / 'speech').mkdir(exist_ok=True)
        (self.output_dir / 'throat_microphone').mkdir(exist_ok=True)
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤
        for name, url in dataset_urls.items():
            print(f"üì• –ó–∞–≥—Ä—É–∂–∞–µ–º {name}...")
            
            if name == 'metadata':
                # –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                response = requests.get(url)
                with open(self.output_dir / 'metadata.csv', 'wb') as f:
                    f.write(response.content)
            else:
                # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–æ–≤
                zip_path = self.output_dir / f'{name}.zip'
                
                response = requests.get(url, stream=True)
                total_size = int(response.headers.get('content-length', 0))
                
                with open(zip_path, 'wb') as f, tqdm(
                    desc=f"Downloading {name}",
                    total=total_size,
                    unit='B',
                    unit_scale=True
                ) as pbar:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                        pbar.update(len(chunk))
                
                # –†–∞—Å–ø–∞–∫–æ–≤–∫–∞
                print(f"üì¶ –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ {name}...")
                with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                    zip_ref.extractall(self.output_dir / name)
                
                # –£–¥–∞–ª–µ–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞
                zip_path.unlink()
        
        print("‚úÖ –î–∞—Ç–∞—Å–µ—Ç Vibravox –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        
    def analyze_dataset(self):
        """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        print("üîÑ –ê–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
        
        # –ü–æ–∏—Å–∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤
        speech_files = list((self.output_dir / 'speech').rglob('*.wav'))
        throat_files = list((self.output_dir / 'throat_microphone').rglob('*.wav'))
        
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞:")
        print(f"   –§–∞–π–ª—ã –æ–±—ã—á–Ω–æ–π —Ä–µ—á–∏: {len(speech_files)}")
        print(f"   –§–∞–π–ª—ã –≥–æ—Ä–ª–æ–≤–æ–≥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞: {len(throat_files)}")
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∞—É–¥–∏–æ
        durations = []
        sample_rates = []
        valid_pairs = 0
        
        for speech_file in tqdm(speech_files[:100], desc="–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞"):  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 100
            try:
                # –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ
                y, sr = librosa.load(speech_file, sr=None)
                duration = len(y) / sr
                
                durations.append(duration)
                sample_rates.append(sr)
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –ø–∞—Ä–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                relative_path = speech_file.relative_to(self.output_dir / 'speech')
                throat_file = self.output_dir / 'throat_microphone' / relative_path
                
                if throat_file.exists():
                    valid_pairs += 1
                    
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {speech_file}: {e}")
        
        print(f"üìà –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ (–Ω–∞ –æ—Å–Ω–æ–≤–µ {len(durations)} —Ñ–∞–π–ª–æ–≤):")
        print(f"   –í–∞–ª–∏–¥–Ω—ã—Ö –ø–∞—Ä: {valid_pairs}")
        print(f"   –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {np.mean(durations):.2f}—Å")
        print(f"   –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏: {np.unique(sample_rates)}")
        print(f"   –î–∏–∞–ø–∞–∑–æ–Ω –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π: {np.min(durations):.2f}—Å - {np.max(durations):.2f}—Å")
        
        return {
            'speech_files': len(speech_files),
            'throat_files': len(throat_files),
            'valid_pairs': valid_pairs,
            'mean_duration': np.mean(durations),
            'sample_rates': np.unique(sample_rates).tolist()
        }
    
    def preprocess_audio_files(self, target_sr=22050, target_duration=3.0):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤"""
        print("üîÑ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤...")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        processed_dir = self.output_dir / 'processed'
        processed_dir.mkdir(exist_ok=True)
        (processed_dir / 'speech').mkdir(exist_ok=True)
        (processed_dir / 'throat_microphone').mkdir(exist_ok=True)
        
        # –ü–æ–∏—Å–∫ –ø–∞—Ä–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        speech_files = list((self.output_dir / 'speech').rglob('*.wav'))
        processed_count = 0
        
        for speech_file in tqdm(speech_files, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ"):
            try:
                # –ü–æ–∏—Å–∫ –ø–∞—Ä–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –≥–æ—Ä–ª–æ–≤–æ–≥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
                relative_path = speech_file.relative_to(self.output_dir / 'speech')
                throat_file = self.output_dir / 'throat_microphone' / relative_path
                
                if not throat_file.exists():
                    continue
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ –æ–±—ã—á–Ω–æ–π —Ä–µ—á–∏
                speech_processed = self._preprocess_single_file(
                    speech_file, target_sr, target_duration
                )
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ –≥–æ—Ä–ª–æ–≤–æ–≥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
                throat_processed = self._preprocess_single_file(
                    throat_file, target_sr, target_duration
                )
                
                if speech_processed is not None and throat_processed is not None:
                    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                    speech_output = processed_dir / 'speech' / relative_path
                    throat_output = processed_dir / 'throat_microphone' / relative_path
                    
                    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
                    speech_output.parent.mkdir(parents=True, exist_ok=True)
                    throat_output.parent.mkdir(parents=True, exist_ok=True)
                    
                    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
                    sf.write(speech_output, speech_processed, target_sr)
                    sf.write(throat_output, throat_processed, target_sr)
                    
                    processed_count += 1
                    
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {speech_file}: {e}")
        
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_count} –ø–∞—Ä —Ñ–∞–π–ª–æ–≤")
        return processed_count
    
    def _preprocess_single_file(self, file_path, target_sr, target_duration):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞"""
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞
            y, sr = librosa.load(file_path, sr=target_sr)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏
            y = librosa.util.normalize(y)
            
            # –£–¥–∞–ª–µ–Ω–∏–µ —Ç–∏—à–∏–Ω—ã
            y, _ = librosa.effects.trim(y, top_db=20)
            
            # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ —Ü–µ–ª–µ–≤–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            target_samples = int(target_sr * target_duration)
            
            if len(y) > target_samples:
                # –û–±—Ä–µ–∑–∫–∞
                y = y[:target_samples]
            elif len(y) < target_samples:
                # –î–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –Ω—É–ª—è–º–∏
                y = np.pad(y, (0, target_samples - len(y)), mode='constant')
            
            # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
            y = self._apply_audio_filters(y, target_sr)
            
            return y
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {file_path}: {e}")
            return None
    
    def _apply_audio_filters(self, y, sr):
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∞—É–¥–∏–æ—Ñ–∏–ª—å—Ç—Ä–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞"""
        # –í—ã—Å–æ–∫–æ—á–∞—Å—Ç–æ—Ç–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –Ω–∏–∑–∫–æ—á–∞—Å—Ç–æ—Ç–Ω–æ–≥–æ —à—É–º–∞
        y = librosa.effects.preemphasis(y)
        
        # –ü–æ–¥–∞–≤–ª–µ–Ω–∏–µ —à—É–º–∞ (–ø—Ä–æ—Å—Ç–∞—è –≤–µ—Ä—Å–∏—è)
        # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –∑–¥–µ—Å—å –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã
        y = librosa.effects.trim(y, top_db=15)[0]
        
        return y
    
    def create_speaker_splits(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –ø–æ –≥–æ–≤–æ—Ä—è—â–∏–º –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        print("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –ø–æ –≥–æ–≤–æ—Ä—è—â–∏–º...")
        
        processed_dir = self.output_dir / 'processed'
        if not processed_dir.exists():
            print("‚ùå –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö")
            return
        
        # –ü–æ–∏—Å–∫ –≤—Å–µ—Ö –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        speech_files = list((processed_dir / 'speech').rglob('*.wav'))
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≥–æ–≤–æ—Ä—è—â–∏—Ö
        speaker_info = {}
        for file_path in speech_files:
            speaker_id = self._extract_speaker_id(file_path)
            if speaker_id not in speaker_info:
                speaker_info[speaker_id] = []
            speaker_info[speaker_id].append(file_path)
        
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ –≥–æ–≤–æ—Ä—è—â–∏—Ö: {len(speaker_info)}")
        for speaker, files in speaker_info.items():
            print(f"   {speaker}: {len(files)} —Ñ–∞–π–ª–æ–≤")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è train/validation/test
        splits = {'train': [], 'validation': [], 'test': []}
        
        for speaker, files in speaker_info.items():
            n_files = len(files)
            
            # 70% - train, 15% - validation, 15% - test
            train_size = int(0.7 * n_files)
            val_size = int(0.15 * n_files)
            
            splits['train'].extend(files[:train_size])
            splits['validation'].extend(files[train_size:train_size + val_size])
            splits['test'].extend(files[train_size + val_size:])
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏
        split_info = {}
        for split_name, files in splits.items():
            split_info[split_name] = [str(f.relative_to(processed_dir / 'speech')) for f in files]
            print(f"üìÅ {split_name}: {len(files)} —Ñ–∞–π–ª–æ–≤")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON
        import json
        with open(self.output_dir / 'data_splits.json', 'w') as f:
            json.dump(split_info, f, indent=2)
        
        print("‚úÖ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å–æ–∑–¥–∞–Ω–æ")
        return split_info
    
    def _extract_speaker_id(self, file_path):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ID –≥–æ–≤–æ—Ä—è—â–µ–≥–æ –∏–∑ –ø—É—Ç–∏ —Ñ–∞–π–ª–∞"""
        parts = str(file_path).split('/')
        for part in parts:
            if 'speaker' in part.lower() or 'spk' in part.lower():
                return part
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        return file_path.parent.name
    
    def generate_dataset_statistics(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        print("üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
        
        processed_dir = self.output_dir / 'processed'
        if not processed_dir.exists():
            print("‚ùå –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö")
            return
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏
        try:
            with open(self.output_dir / 'data_splits.json', 'r') as f:
                splits = json.load(f)
        except FileNotFoundError:
            print("‚ùå –°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö")
            return
        
        stats = {
            'total_files': 0,
            'total_duration': 0.0,
            'speakers': set(),
            'splits': {}
        }
        
        for split_name, files in splits.items():
            split_stats = {
                'files': len(files),
                'duration': 0.0,
                'speakers': set()
            }
            
            for file_rel_path in tqdm(files, desc=f"–ê–Ω–∞–ª–∏–∑ {split_name}"):
                try:
                    file_path = processed_dir / 'speech' / file_rel_path
                    y, sr = librosa.load(file_path, sr=None)
                    duration = len(y) / sr
                    
                    split_stats['duration'] += duration
                    speaker = self._extract_speaker_id(file_path)
                    split_stats['speakers'].add(speaker)
                    stats['speakers'].add(speaker)
                    
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {file_rel_path}: {e}")
            
            split_stats['speakers'] = len(split_stats['speakers'])
            stats['splits'][split_name] = split_stats
            stats['total_files'] += split_stats['files']
            stats['total_duration'] += split_stats['duration']
        
        stats['speakers'] = len(stats['speakers'])
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        with open(self.output_dir / 'dataset_stats.json', 'w') as f:
            json.dump(stats, f, indent=2, default=str)
        
        # –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        print("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞:")
        print(f"   –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤: {stats['total_files']}")
        print(f"   –û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {stats['total_duration']:.1f} —Å–µ–∫ ({stats['total_duration']/3600:.1f} —á–∞—Å–æ–≤)")
        print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–æ–≤–æ—Ä—è—â–∏—Ö: {stats['speakers']}")
        
        for split_name, split_stats in stats['splits'].items():
            print(f"   {split_name.capitalize()}:")
            print(f"     –§–∞–π–ª—ã: {split_stats['files']}")
            print(f"     –ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {split_stats['duration']:.1f} —Å–µ–∫")
            print(f"     –ì–æ–≤–æ—Ä—è—â–∏—Ö: {split_stats['speakers']}")
        
        return stats

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
    parser = argparse.ArgumentParser(description='–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö Vibravox –¥–ª—è VoiceX')
    parser.add_argument('--output_dir', type=str, default='./vibravox_data',
                       help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö')
    parser.add_argument('--download', action='store_true',
                       help='–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç Vibravox')
    parser.add_argument('--preprocess', action='store_true',
                       help='–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∞—É–¥–∏–æ—Ñ–∞–π–ª—ã')
    parser.add_argument('--analyze', action='store_true',
                       help='–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç')
    parser.add_argument('--create_splits', action='store_true',
                       help='–°–æ–∑–¥–∞—Ç—å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val/test')
    parser.add_argument('--stats', action='store_true',
                       help='–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É')
    parser.add_argument('--all', action='store_true',
                       help='–í—ã–ø–æ–ª–Ω–∏—Ç—å –≤—Å–µ —ç—Ç–∞–ø—ã –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏')
    parser.add_argument('--target_sr', type=int, default=22050,
                       help='–¶–µ–ª–µ–≤–∞—è —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏')
    parser.add_argument('--target_duration', type=float, default=3.0,
                       help='–¶–µ–ª–µ–≤–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ñ–∞–π–ª–æ–≤ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö')
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
    preparator = VibravoxDataPreparator(args.output_dir)
    
    print("üöÄ –ó–∞–ø—É—Å–∫ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö Vibravox –¥–ª—è VoiceX")
    print("=" * 50)
    
    try:
        if args.all or args.download:
            preparator.download_vibravox_dataset()
        
        if args.all or args.analyze:
            analysis_results = preparator.analyze_dataset()
        
        if args.all or args.preprocess:
            processed_count = preparator.preprocess_audio_files(
                target_sr=args.target_sr,
                target_duration=args.target_duration
            )
        
        if args.all or args.create_splits:
            split_info = preparator.create_speaker_splits()
        
        if args.all or args.stats:
            stats = preparator.generate_dataset_statistics()
        
        print("=" * 50)
        print("üéâ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        print(f"üìÅ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {args.output_dir}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    import sys
    sys.exit(main())