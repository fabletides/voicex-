#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ VoiceX
–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ
"""

import os
import json
import numpy as np
import librosa
import soundfile as sf
import tensorflow as tf
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.spatial.distance import cosine
from sklearn.metrics import mean_squared_error, mean_absolute_error
import argparse
from tqdm import tqdm
import joblib
import warnings
warnings.filterwarnings('ignore')

class VoiceXModelTester:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ VoiceX"""
    
    def __init__(self, model_path, config_path, scaler_path):
        self.model_path = Path(model_path)
        self.config_path = Path(config_path)
        self.scaler_path = Path(scaler_path)
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        with open(config_path, 'r') as f:
            self.config = json.load(f)
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        if str(model_path).endswith('.tflite'):
            self.model = self._load_tflite_model()
            self.model_type = 'tflite'
        else:
            self.model = tf.keras.models.load_model(model_path)
            self.model_type = 'keras'
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–∫–µ–π–ª–µ—Ä–∞
        self.scaler = joblib.load(scaler_path)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ
        self.sample_rate = self.config.get('sample_rate', 22050)
        self.duration = self.config.get('duration', 3.0)
        self.n_fft = self.config.get('n_fft', 2048)
        self.hop_length = self.config.get('hop_length', 512)
        self.n_mels = self.config.get('n_mels', 128)
        self.n_mfcc = self.config.get('n_mfcc', 13)
        
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {model_path}")
        print(f"üìä –¢–∏–ø –º–æ–¥–µ–ª–∏: {self.model_type}")
        print(f"üîß –í—Ö–æ–¥–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {self.config.get('input_dim', '–Ω–µ —É–∫–∞–∑–∞–Ω–∞')}")
        print(f"üéØ –í—ã—Ö–æ–¥–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {self.config.get('output_dim', '–Ω–µ —É–∫–∞–∑–∞–Ω–∞')}")
    
    def _load_tflite_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ TensorFlow Lite –º–æ–¥–µ–ª–∏"""
        interpreter = tf.lite.Interpreter(model_path=str(self.model_path))
        interpreter.allocate_tensors()
        return interpreter
    
    def preprocess_throat_signal(self, audio_signal, sr):
        """
        –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–≥–Ω–∞–ª–∞ —Å –≥–æ—Ä–ª–æ–≤–æ–≥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
        –í–∫–ª—é—á–∞–µ—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é —à—É–º–∞ –∏ —É—Å–∏–ª–µ–Ω–∏–µ –ø–æ–ª–µ–∑–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞
        """
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∞–º–ø–ª–∏—Ç—É–¥—ã
        audio_signal = librosa.util.normalize(audio_signal)
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–æ–ª–æ—Å–æ–≤–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞ –¥–ª—è –≥–æ–ª–æ—Å–æ–≤—ã—Ö —á–∞—Å—Ç–æ—Ç (80-4000 Hz)
        from scipy import signal
        nyquist = sr / 2
        low = 80 / nyquist
        high = 4000 / nyquist
        b, a = signal.butter(4, [low, high], btype='band')
        filtered_signal = signal.filtfilt(b, a, audio_signal)
        
        # –ü–æ–¥–∞–≤–ª–µ–Ω–∏–µ —à—É–º–∞ —á–µ—Ä–µ–∑ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–µ –≤—ã—á–∏—Ç–∞–Ω–∏–µ
        stft = librosa.stft(filtered_signal, n_fft=self.n_fft, hop_length=self.hop_length)
        magnitude = np.abs(stft)
        phase = np.angle(stft)
        
        # –û—Ü–µ–Ω–∫–∞ —à—É–º–∞ –∏–∑ –ø–µ—Ä–≤—ã—Ö –∏ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 10% —Å–∏–≥–Ω–∞–ª–∞
        noise_frames = int(0.1 * magnitude.shape[1])
        noise_profile = np.mean(magnitude[:, :noise_frames], axis=1, keepdims=True)
        noise_profile = np.maximum(noise_profile, 
                                 np.mean(magnitude[:, -noise_frames:], axis=1, keepdims=True))
        
        # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–µ –≤—ã—á–∏—Ç–∞–Ω–∏–µ —Å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–º –ø–æ–¥–∞–≤–ª–µ–Ω–∏—è
        alpha = 2.0  # –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø–æ–¥–∞–≤–ª–µ–Ω–∏—è —à—É–º–∞
        magnitude_clean = magnitude - alpha * noise_profile
        magnitude_clean = np.maximum(magnitude_clean, 0.1 * magnitude)
        
        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞
        stft_clean = magnitude_clean * np.exp(1j * phase)
        cleaned_signal = librosa.istft(stft_clean, hop_length=self.hop_length)
        
        return cleaned_signal
    
    def extract_features_from_audio(self, audio_path, is_throat=False):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞"""
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ
            y, sr = librosa.load(audio_path, sr=self.sample_rate)
            
            # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Å–∏–≥–Ω–∞–ª–æ–≤ –≥–æ—Ä–ª–æ–≤–æ–≥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
            if is_throat:
                y = self.preprocess_throat_signal(y, sr)
            
            # –û–±—Ä–µ–∑–∫–∞/–¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–æ –Ω—É–∂–Ω–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            target_length = int(self.sample_rate * self.duration)
            if len(y) > target_length:
                # –ë–µ—Ä–µ–º —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—É—é —á–∞—Å—Ç—å
                start = (len(y) - target_length) // 2
                y = y[start:start + target_length]
            else:
                y = np.pad(y, (0, target_length - len(y)), mode='constant')
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            features = []
            
            # 1. Mel-spectrogram (–æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–∏–∑–Ω–∞–∫ –¥–ª—è –≥–æ–ª–æ—Å–∞)
            mel_spec = librosa.feature.melspectrogram(
                y=y, 
                sr=sr,
                n_fft=self.n_fft,
                hop_length=self.hop_length,
                n_mels=self.n_mels,
                fmin=80,  # –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ –¥–ª—è –≥–æ–ª–æ—Å–∞
                fmax=8000  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞
            )
            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)
            features.extend(mel_spec_db.flatten())
            
            # 2. MFCC (–∫–µ–ø—Å—Ç—Ä–∞–ª—å–Ω—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã)
            mfcc = librosa.feature.mfcc(
                y=y, 
                sr=sr, 
                n_mfcc=self.n_mfcc,
                n_fft=self.n_fft,
                hop_length=self.hop_length
            )
            features.extend(mfcc.flatten())
            
            # 3. –•—Ä–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            chroma = librosa.feature.chroma_stft(
                y=y, 
                sr=sr,
                n_fft=self.n_fft,
                hop_length=self.hop_length
            )
            features.extend(chroma.flatten())
            
            # 4. –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]
            spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]
            zero_crossing_rate = librosa.feature.zero_crossing_rate(y)[0]
            
            features.extend(spectral_centroids)
            features.extend(spectral_rolloff)
            features.extend(spectral_bandwidth)
            features.extend(zero_crossing_rate)
            
            # 5. Pitch (F0) - –æ—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞
            f0, voiced_flag, voiced_probs = librosa.pyin(
                y, 
                fmin=librosa.note_to_hz('C2'), 
                fmax=librosa.note_to_hz('C7'),
                sr=sr,
                frame_length=self.n_fft,
                hop_length=self.hop_length
            )
            f0 = np.nan_to_num(f0, nan=0.0)
            
            # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –¥–ª–∏–Ω—ã f0 —Å –¥—Ä—É–≥–∏–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
            target_f0_length = len(spectral_centroids)
            if len(f0) > target_f0_length:
                f0 = f0[:target_f0_length]
            else:
                f0 = np.pad(f0, (0, target_f0_length - len(f0)), mode='constant')
            
            features.extend(f0)
            features.extend(voiced_probs[:len(f0)] if voiced_probs is not None else np.zeros(len(f0)))
            
            # 6. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–∞
            if is_throat:
                # –î–ª—è –≥–æ—Ä–ª–æ–≤–æ–≥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –¥–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                # –≠–Ω–µ—Ä–≥–∏—è –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —á–∞—Å—Ç–æ—Ç–Ω—ã—Ö –ø–æ–ª–æ—Å–∞—Ö
                freqs = librosa.fft_frequencies(sr=sr, n_fft=self.n_fft)
                stft = librosa.stft(y, n_fft=self.n_fft, hop_length=self.hop_length)
                magnitude = np.abs(stft)
                
                # –≠–Ω–µ—Ä–≥–∏—è –≤ –Ω–∏–∑–∫–∏—Ö —á–∞—Å—Ç–æ—Ç–∞—Ö (80-300 Hz) - —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ —á–∞—Å—Ç–æ—Ç—ã
                low_freq_mask = (freqs >= 80) & (freqs <= 300)
                low_freq_energy = np.mean(magnitude[low_freq_mask, :], axis=0)
                features.extend(low_freq_energy)
                
                # –≠–Ω–µ—Ä–≥–∏—è –≤ —Å—Ä–µ–¥–Ω–∏—Ö —á–∞—Å—Ç–æ—Ç–∞—Ö (300-2000 Hz) - —Ñ–æ—Ä–º–∞–Ω—Ç–Ω—ã–µ —á–∞—Å—Ç–æ—Ç—ã
                mid_freq_mask = (freqs >= 300) & (freqs <= 2000)
                mid_freq_energy = np.mean(magnitude[mid_freq_mask, :], axis=0)
                features.extend(mid_freq_energy)
            
            return np.array(features, dtype=np.float32)
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ {audio_path}: {e}")
            return None
    
    def predict_voice_conversion(self, throat_features):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            expected_input_dim = self.config.get('input_dim')
            if expected_input_dim and len(throat_features) != expected_input_dim:
                print(f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ {len(throat_features)} != –æ–∂–∏–¥–∞–µ–º–æ–π {expected_input_dim}")
                # –û–±—Ä–µ–∑–∫–∞ –∏–ª–∏ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–æ –Ω—É–∂–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
                if len(throat_features) > expected_input_dim:
                    throat_features = throat_features[:expected_input_dim]
                else:
                    throat_features = np.pad(throat_features, (0, expected_input_dim - len(throat_features)), mode='constant')
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            throat_features_scaled = self.scaler.transform(throat_features.reshape(1, -1))
            
            if self.model_type == 'keras':
                # Keras –º–æ–¥–µ–ª—å
                prediction = self.model.predict(throat_features_scaled, verbose=0)
            else:
                # TensorFlow Lite –º–æ–¥–µ–ª—å
                input_details = self.model.get_input_details()
                output_details = self.model.get_output_details()
                
                self.model.set_tensor(input_details[0]['index'], throat_features_scaled.astype(np.float32))
                self.model.invoke()
                prediction = self.model.get_tensor(output_details[0]['index'])
            
            return prediction[0]
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return None
    
    def convert_features_to_audio(self, features, output_path, target_sr=22050):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –æ–±—Ä–∞—Ç–Ω–æ –≤ –∞—É–¥–∏–æ"""
        try:
            # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
            n_frames = int(self.duration * target_sr / self.hop_length)
            mel_spec_size = self.n_mels * n_frames
            
            if len(features) < mel_spec_size:
                print(f"‚ùå –û—à–∏–±–∫–∞: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏. –ü–æ–ª—É—á–µ–Ω–æ: {len(features)}, –Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º: {mel_spec_size}")
                return False
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ mel-spectrogram
            mel_spec_flat = features[:mel_spec_size]
            mel_spec = mel_spec_flat.reshape(self.n_mels, n_frames)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑ dB –≤ power
            mel_spec_power = librosa.db_to_power(mel_spec)
            
            # –†–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Griffin-Lim —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            audio = librosa.feature.inverse.mel_to_audio(
                mel_spec_power,
                sr=target_sr,
                hop_length=self.hop_length,
                n_fft=self.n_fft,
                fmin=80,
                fmax=8000,
                n_iter=64  # –±–æ–ª—å—à–µ –∏—Ç–µ—Ä–∞—Ü–∏–π –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
            )
            
            # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞
            # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–∫–æ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
            window_size = int(0.02 * target_sr)  # 20–º—Å –æ–∫–Ω–æ
            if len(audio) > window_size:
                fade_in = np.linspace(0, 1, window_size)
                fade_out = np.linspace(1, 0, window_size)
                audio[:window_size] *= fade_in
                audio[-window_size:] *= fade_out
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –ø–∏–∫–æ–≤
            audio = librosa.util.normalize(audio) * 0.8
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            sf.write(output_path, audio, target_sr)
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ –∞—É–¥–∏–æ: {e}")
            return False
    
    def calculate_voice_quality_metrics(self, predicted_features, target_features):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –≥–æ–ª–æ—Å–∞"""
        # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–º—É —Ä–∞–∑–º–µ—Ä—É
        min_size = min(len(predicted_features), len(target_features))
        pred_trimmed = predicted_features[:min_size]
        target_trimmed = target_features[:min_size]
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        mse = mean_squared_error(target_trimmed, pred_trimmed)
        mae = mean_absolute_error(target_trimmed, pred_trimmed)
        cosine_sim = 1 - cosine(target_trimmed, pred_trimmed)
        
        # –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –≥–æ–ª–æ—Å–∞
        # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ü–∏—Ä—Å–æ–Ω–∞
        correlation = np.corrcoef(pred_trimmed, target_trimmed)[0, 1]
        if np.isnan(correlation):
            correlation = 0.0
        
        # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–∞—è –¥–∏—Å—Ç–∞–Ω—Ü–∏—è
        spectral_distance = np.sqrt(np.mean((pred_trimmed - target_trimmed) ** 2))
        
        # Signal-to-Noise Ratio (SNR)
        signal_power = np.mean(target_trimmed ** 2)
        noise_power = np.mean((pred_trimmed - target_trimmed) ** 2)
        snr = 10 * np.log10(signal_power / (noise_power + 1e-10))
        
        return {
            'mse': float(mse),
            'mae': float(mae),
            'cosine_similarity': float(cosine_sim),
            'correlation': float(correlation),
            'spectral_distance': float(spectral_distance),
            'snr_db': float(snr)
        }
    
    def test_single_sample(self, throat_audio_path, target_audio_path=None):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–º –æ–±—Ä–∞–∑—Ü–µ"""
        print(f"üîÑ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {throat_audio_path}")
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –≥–æ—Ä–ª–æ–≤–æ–≥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
        throat_features = self.extract_features_from_audio(throat_audio_path, is_throat=True)
        if throat_features is None:
            return None
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        predicted_features = self.predict_voice_conversion(throat_features)
        if predicted_features is None:
            return None
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        output_path = Path(throat_audio_path).parent / f"converted_{Path(throat_audio_path).stem}.wav"
        success = self.convert_features_to_audio(predicted_features, output_path)
        
        result = {
            'input_file': str(throat_audio_path),
            'output_file': str(output_path) if success else None,
            'conversion_success': success,
            'throat_features_shape': throat_features.shape,
            'predicted_features_shape': predicted_features.shape
        }
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Ü–µ–ª–µ–≤–æ–π —Ñ–∞–π–ª, –≤—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        if target_audio_path and Path(target_audio_path).exists():
            target_features = self.extract_features_from_audio(target_audio_path, is_throat=False)
            if target_features is not None:
                metrics = self.calculate_voice_quality_metrics(predicted_features, target_features)
                result.update(metrics)
                result['target_file'] = str(target_audio_path)
        
        return result
    
    def test_dataset(self, data_path, output_dir, num_samples=50):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ"""
        print(f"üîÑ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ: {data_path}")
        
        data_path = Path(data_path)
        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True)
        
        # –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ –≥–æ—Ä–ª–æ–≤–æ–≥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
        throat_files = list(data_path.rglob('*throat*.wav')) + list(data_path.rglob('*vibro*.wav'))
        
        if len(throat_files) == 0:
            # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –≤ –ø–æ–¥–ø–∞–ø–∫–∞—Ö
            throat_files = list((data_path / 'throat_microphone').rglob('*.wav')) if (data_path / 'throat_microphone').exists() else []
            
        if len(throat_files) == 0:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã –≥–æ—Ä–ª–æ–≤–æ–≥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞")
            print("üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É:")
            print("   data_path/")
            print("   ‚îú‚îÄ‚îÄ throat_microphone/")
            print("   ‚îÇ   ‚îî‚îÄ‚îÄ *.wav")
            print("   ‚îî‚îÄ‚îÄ speech/")
            print("       ‚îî‚îÄ‚îÄ *.wav")
            return None
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–µ—Å—Ç–æ–≤
        throat_files = throat_files[:num_samples]
        
        results = []
        successful_conversions = 0
        
        for throat_file in tqdm(throat_files, desc="–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"):
            # –ü–æ–∏—Å–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞ –æ–±—ã—á–Ω–æ–π —Ä–µ—á–∏
            relative_path = throat_file.name
            speech_file = None
            
            # –ò—â–µ–º –≤ —Ä–∞–∑–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö
            speech_dirs = [data_path / 'speech', data_path / 'normal', data_path / 'target']
            for speech_dir in speech_dirs:
                if speech_dir.exists():
                    potential_speech = speech_dir / relative_path
                    if potential_speech.exists():
                        speech_file = potential_speech
                        break
            
            target_file = str(speech_file) if speech_file else None
            
            # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
            result = self.test_single_sample(str(throat_file), target_file)
            
            if result:
                results.append(result)
                if result['conversion_success']:
                    successful_conversions += 1
                    
                    # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
                    if result['output_file']:
                        output_file = output_dir / f"sample_{len(results):03d}_converted.wav"
                        try:
                            import shutil
                            shutil.copy2(result['output_file'], output_file)
                            result['demo_file'] = str(output_file)
                        except Exception as e:
                            print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        results_path = output_dir / 'test_results.json'
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, default=str, ensure_ascii=False)
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ–±—â–∏—Ö –º–µ—Ç—Ä–∏–∫
        metrics_results = self._calculate_overall_metrics(results)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        metrics_path = output_dir / 'test_metrics.json'
        with open(metrics_path, 'w', encoding='utf-8') as f:
            json.dump(metrics_results, f, indent=2, ensure_ascii=False)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        self._create_test_report(output_dir, results, metrics_results)
        
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:")
        print(f"   –í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤: {len(results)}")
        print(f"   –£—Å–ø–µ—à–Ω—ã—Ö –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–π: {successful_conversions}")
        print(f"   –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {successful_conversions/len(results)*100:.1f}%")
        
        if 'mse' in metrics_results:
            print(f"   –°—Ä–µ–¥–Ω–∏–π MSE: {metrics_results['mse']:.6f}")
            print(f"   –°—Ä–µ–¥–Ω–∏–π MAE: {metrics_results['mae']:.6f}")
            print(f"   –°—Ä–µ–¥–Ω—è—è –∫–æ—Å–∏–Ω—É—Å–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å: {metrics_results['cosine_similarity']:.3f}")
            print(f"   –°—Ä–µ–¥–Ω–∏–π SNR: {metrics_results['snr_db']:.2f} dB")
        
        return results
    
    def _calculate_overall_metrics(self, results):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ–±—â–∏—Ö –º–µ—Ç—Ä–∏–∫"""
        metrics = {}
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        results_with_metrics = [r for r in results if 'mse' in r]
        
        if results_with_metrics:
            metric_keys = ['mse', 'mae', 'cosine_similarity', 'correlation', 'spectral_distance', 'snr_db']
            
            for key in metric_keys:
                values = [r[key] for r in results_with_metrics if key in r]
                if values:
                    metrics[key] = np.mean(values)
                    metrics[f'{key}_std'] = np.std(values)
                    metrics[f'{key}_min'] = np.min(values)
                    metrics[f'{key}_max'] = np.max(values)
        
        metrics['total_samples'] = len(results)
        metrics['successful_conversions'] = len([r for r in results if r['conversion_success']])
        metrics['success_rate'] = metrics['successful_conversions'] / metrics['total_samples'] if metrics['total_samples'] > 0 else 0
        
        return metrics
    
    def _create_test_report(self, output_dir, results, metrics):
        """–°–æ–∑–¥–∞–Ω–∏–µ HTML –æ—Ç—á–µ—Ç–∞ –æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏"""
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>VoiceX Testing Report</title>
            <meta charset="utf-8">
            <style>
                body {{ font-family: Arial, sans-serif; margin: 40px; background-color: #f5f5f5; }}
                .container {{ max-width: 1200px; margin: 0 auto; background-color: white; padding: 30px; border-radius: 10px; box-shadow: 0 0 20px rgba(0,0,0,0.1); }}
                .header {{ text-align: center; margin-bottom: 30px; }}
                .metrics {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin: 20px 0; }}
                .metric-card {{ background-color: #f8f9fa; padding: 20px; border-radius: 8px; border-left: 4px solid #007bff; }}
                .metric-value {{ font-size: 24px; font-weight: bold; color: #007bff; }}
                .success {{ color: #28a745; }}
                .warning {{ color: #ffc107; }}
                .error {{ color: #dc3545; }}
                .samples {{ margin-top: 30px; }}
                .sample {{ background-color: #f8f9fa; margin: 10px 0; padding: 15px; border-radius: 5px; }}
                table {{ width: 100%; border-collapse: collapse; margin-top: 20px; }}
                th, td {{ padding: 10px; text-align: left; border-bottom: 1px solid #ddd; }}
                th {{ background-color: #007bff; color: white; }}
            </style>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h1>üéôÔ∏è VoiceX Model Testing Report</h1>
                    <p>–û—Ç—á–µ—Ç –æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –º–æ–¥–µ–ª–∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–∞</p>
                </div>
                
                <div class="metrics">
                    <div class="metric-card">
                        <h3>–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞</h3>
                        <div class="metric-value success">{metrics['total_samples']}</div>
                        <p>–í—Å–µ–≥–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ –æ–±—Ä–∞–∑—Ü–æ–≤</p>
                    </div>
                    
                    <div class="metric-card">
                        <h3>–£—Å–ø–µ—à–Ω–æ—Å—Ç—å –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏</h3>
                        <div class="metric-value {'success' if metrics['success_rate'] > 0.8 else 'warning' if metrics['success_rate'] > 0.5 else 'error'}">{metrics['success_rate']*100:.1f}%</div>
                        <p>{metrics['successful_conversions']} –∏–∑ {metrics['total_samples']} —É—Å–ø–µ—à–Ω—ã—Ö</p>
                    </div>
        """
        
        if 'mse' in metrics:
            html_content += f"""
                    <div class="metric-card">
                        <h3>–ö–∞—á–µ—Å—Ç–≤–æ (MSE)</h3>
                        <div class="metric-value">{metrics['mse']:.6f}</div>
                        <p>–°—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞</p>
                    </div>
                    
                    <div class="metric-card">
                        <h3>–°—Ö–æ–∂–µ—Å—Ç—å (Cosine)</h3>
                        <div class="metric-value success">{metrics['cosine_similarity']:.3f}</div>
                        <p>–ö–æ—Å–∏–Ω—É—Å–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å</p>
                    </div>
                    
                    <div class="metric-card">
                        <h3>SNR</h3>
                        <div class="metric-value">{metrics['snr_db']:.2f} dB</div>
                        <p>–û—Ç–Ω–æ—à–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª/—à—É–º</p>
                    </div>
            """
        
        html_content += """
                </div>
                
                <h2>üìà –î–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏</h2>
                <table>
                    <tr>
                        <th>–ú–µ—Ç—Ä–∏–∫–∞</th>
                        <th>–°—Ä–µ–¥–Ω–µ–µ</th>
                        <th>–°—Ç–¥. –æ—Ç–∫–ª.</th>
                        <th>–ú–∏–Ω–∏–º—É–º</th>
                        <th>–ú–∞–∫—Å–∏–º—É–º</th>
                    </tr>
        """
        
        if 'mse' in metrics:
            metric_names = {
                'mse': 'MSE',
                'mae': 'MAE', 
                'cosine_similarity': 'Cosine Similarity',
                'correlation': 'Correlation',
                'snr_db': 'SNR (dB)'
            }
            
            for key, name in metric_names.items():
                if key in metrics:
                    html_content += f"""
                    <tr>
                        <td>{name}</td>
                        <td>{metrics[key]:.6f}</td>
                        <td>{metrics.get(f'{key}_std', 0):.6f}</td>
                        <td>{metrics.get(f'{key}_min', 0):.6f}</td>
                        <td>{metrics.get(f'{key}_max', 0):.6f}</td>
                    </tr>
                    """
        
        html_content += """
                </table>
                
                <h2>üî¨ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤</h2>
                <div style="background-color: #e7f3ff; padding: 20px; border-radius: 8px; margin: 20px 0;">
                    <h3>–ö–∞–∫ —á–∏—Ç–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏:</h3>
                    <ul>
                        <li><strong>MSE (Mean Squared Error):</strong> –ß–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –ª—É—á—à–µ. –•–æ—Ä–æ—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è < 0.01</li>
                        <li><strong>Cosine Similarity:</strong> –ß–µ–º –±–ª–∏–∂–µ –∫ 1, —Ç–µ–º –ª—É—á—à–µ. –•–æ—Ä–æ—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è > 0.7</li>
                        <li><strong>SNR (Signal-to-Noise Ratio):</strong> –ß–µ–º –±–æ–ª—å—à–µ, —Ç–µ–º –ª—É—á—à–µ. –•–æ—Ä–æ—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è > 10 dB</li>
                        <li><strong>Correlation:</strong> –ß–µ–º –±–ª–∏–∂–µ –∫ 1, —Ç–µ–º –ª—É—á—à–µ. –•–æ—Ä–æ—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è > 0.6</li>
                    </ul>
                </div>
                
                <div style="margin-top: 30px; padding: 20px; background-color: #f0f8ff; border-radius: 8px;">
                    <h3>üí° –û –º–æ–¥–µ–ª–∏ VoiceX:</h3>
                    <p>VoiceX –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–∞, –ø—Ä–µ–æ–±—Ä–∞–∑—É—è –≤–∏–±—Ä–∞—Ü–∏–∏ –≥–æ—Ä–ª–æ–≤–æ–≥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –≤ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—É—é —Ä–µ—á—å. –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≥–æ–ª–æ—Å–∞ –ø–∞—Ü–∏–µ–Ω—Ç–∞.</p>
                    <p><strong>–ü—Ä–æ—Ü–µ—Å—Å:</strong> –ì–æ—Ä–ª–æ–≤—ã–µ –≤–∏–±—Ä–∞—Ü–∏–∏ ‚Üí –û—á–∏—Å—Ç–∫–∞ —Å–∏–≥–Ω–∞–ª–∞ ‚Üí ML –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è ‚Üí –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –≥–æ–ª–æ—Å</p>
                </div>
            </div>
        </body>
        </html>
        """
        
        report_path = output_dir / 'test_report.html'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"üìÑ HTML –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {report_path}")
    
    def create_demo_comparison(self, throat_file, speech_file, output_dir):
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ-—Å—Ä–∞–≤–Ω–µ–Ω–∏—è –æ—Ä–∏–≥–∏–Ω–∞–ª vs –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π"""
        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True)
        
        print(f"üîÑ –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ-—Å—Ä–∞–≤–Ω–µ–Ω–∏—è...")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
        result = self.test_single_sample(throat_file, speech_file)
        
        if not result or not result['conversion_success']:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é")
            return None
        
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
            throat_audio, sr1 = librosa.load(throat_file, sr=22050)
            converted_audio, sr3 = librosa.load(result['output_file'], sr=22050)
            
            speech_audio = None
            if speech_file and Path(speech_file).exists():
                speech_audio, sr2 = librosa.load(speech_file, sr=22050)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
            num_plots = 3 if speech_audio is not None else 2
            fig, axes = plt.subplots(num_plots, 2, figsize=(15, 5*num_plots))
            
            if num_plots == 2:
                axes = axes.reshape(2, 2)
            
            # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã
            time_samples = min(len(throat_audio), sr1*3)  # –ü–µ—Ä–≤—ã–µ 3 —Å–µ–∫—É–Ω–¥—ã
            axes[0, 0].plot(np.linspace(0, time_samples/sr1, time_samples), throat_audio[:time_samples])
            axes[0, 0].set_title('Throat Microphone Signal')
            axes[0, 0].set_xlabel('Time (s)')
            axes[0, 0].set_ylabel('Amplitude')
            axes[0, 0].grid(True, alpha=0.3)
            
            time_samples_conv = min(len(converted_audio), sr3*3)
            axes[1, 0].plot(np.linspace(0, time_samples_conv/sr3, time_samples_conv), converted_audio[:time_samples_conv])
            axes[1, 0].set_title('Converted Speech Signal (VoiceX Output)')
            axes[1, 0].set_xlabel('Time (s)')
            axes[1, 0].set_ylabel('Amplitude')
            axes[1, 0].grid(True, alpha=0.3)
            
            if speech_audio is not None:
                time_samples_orig = min(len(speech_audio), sr2*3)
                axes[2, 0].plot(np.linspace(0, time_samples_orig/sr2, time_samples_orig), speech_audio[:time_samples_orig])
                axes[2, 0].set_title('Original Speech Signal')
                axes[2, 0].set_xlabel('Time (s)')
                axes[2, 0].set_ylabel('Amplitude')
                axes[2, 0].grid(True, alpha=0.3)
            
            # –°–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã
            D1 = librosa.stft(throat_audio[:sr1*3])
            D3 = librosa.stft(converted_audio[:sr3*3])
            
            im1 = axes[0, 1].imshow(librosa.amplitude_to_db(np.abs(D1)), 
                                   aspect='auto', origin='lower', cmap='viridis')
            axes[0, 1].set_title('Throat Microphone Spectrogram')
            axes[0, 1].set_xlabel('Time Frames')
            axes[0, 1].set_ylabel('Frequency Bins')
            plt.colorbar(im1, ax=axes[0, 1])
            
            im3 = axes[1, 1].imshow(librosa.amplitude_to_db(np.abs(D3)), 
                                   aspect='auto', origin='lower', cmap='viridis')
            axes[1, 1].set_title('Converted Speech Spectrogram')
            axes[1, 1].set_xlabel('Time Frames')
            axes[1, 1].set_ylabel('Frequency Bins')
            plt.colorbar(im3, ax=axes[1, 1])
            
            if speech_audio is not None:
                D2 = librosa.stft(speech_audio[:sr2*3])
                im2 = axes[2, 1].imshow(librosa.amplitude_to_db(np.abs(D2)), 
                                       aspect='auto', origin='lower', cmap='viridis')
                axes[2, 1].set_title('Original Speech Spectrogram')
                axes[2, 1].set_xlabel('Time Frames')
                axes[2, 1].set_ylabel('Frequency Bins')
                plt.colorbar(im2, ax=axes[2, 1])
            
            plt.tight_layout()
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
            comparison_path = output_dir / 'demo_comparison.png'
            plt.savefig(comparison_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ –¥–ª—è –¥–µ–º–æ
            import shutil
            shutil.copy2(throat_file, output_dir / 'input_throat.wav')
            if speech_file and Path(speech_file).exists():
                shutil.copy2(speech_file, output_dir / 'target_speech.wav')
            shutil.copy2(result['output_file'], output_dir / 'converted_speech.wav')
            
            print(f"‚úÖ –î–µ–º–æ-—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ –≤ {output_dir}")
            
            # –°–æ–∑–¥–∞–Ω–∏–µ HTML –¥–µ–º–æ
            self._create_html_demo(output_dir, result)
            
            return {
                'comparison_image': str(comparison_path),
                'input_audio': str(output_dir / 'input_throat.wav'),
                'target_audio': str(output_dir / 'target_speech.wav') if speech_file else None,
                'converted_audio': str(output_dir / 'converted_speech.wav'),
                'metrics': {k: v for k, v in result.items() if k in ['mse', 'mae', 'cosine_similarity', 'snr_db']}
            }
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥–µ–º–æ: {e}")
            return None
    
    def _create_html_demo(self, output_dir, result):
        """–°–æ–∑–¥–∞–Ω–∏–µ HTML –¥–µ–º–æ —Å –∞—É–¥–∏–æ–ø–ª–µ–µ—Ä–∞–º–∏"""
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>VoiceX Demo Comparison</title>
            <meta charset="utf-8">
            <style>
                body {{ 
                    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
                    margin: 0; 
                    padding: 40px; 
                    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                    color: #333;
                }}
                .container {{
                    max-width: 1000px;
                    margin: 0 auto;
                    background: white;
                    border-radius: 20px;
                    padding: 40px;
                    box-shadow: 0 20px 40px rgba(0,0,0,0.1);
                }}
                .header {{
                    text-align: center;
                    margin-bottom: 40px;
                    border-bottom: 3px solid #667eea;
                    padding-bottom: 20px;
                }}
                .header h1 {{
                    color: #667eea;
                    font-size: 2.5em;
                    margin-bottom: 10px;
                }}
                .audio-section {{ 
                    margin: 30px 0; 
                    padding: 25px; 
                    border: 2px solid #e0e0e0; 
                    border-radius: 15px;
                    background: linear-gradient(145deg, #f8f9fa, #e9ecef);
                    transition: all 0.3s ease;
                }}
                .audio-section:hover {{
                    border-color: #667eea;
                    box-shadow: 0 5px 15px rgba(102, 126, 234, 0.2);
                }}
                .audio-section h3 {{
                    color: #495057;
                    font-size: 1.3em;
                    margin-bottom: 15px;
                }}
                audio {{
                    width: 100%;
                    height: 50px;
                    border-radius: 10px;
                }}
                .metrics {{ 
                    background: linear-gradient(145deg, #e3f2fd, #bbdefb); 
                    padding: 25px; 
                    margin: 30px 0; 
                    border-radius: 15px;
                    border-left: 5px solid #2196f3;
                }}
                .metrics h3 {{
                    color: #1976d2;
                    font-size: 1.4em;
                    margin-bottom: 20px;
                }}
                .metric-grid {{
                    display: grid;
                    grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
                    gap: 15px;
                }}
                .metric-item {{
                    background: white;
                    padding: 15px;
                    border-radius: 10px;
                    text-align: center;
                    box-shadow: 0 2px 10px rgba(0,0,0,0.1);
                }}
                .metric-value {{
                    font-size: 1.5em;
                    font-weight: bold;
                    color: #1976d2;
                }}
                img {{ 
                    max-width: 100%; 
                    height: auto; 
                    border-radius: 15px;
                    box-shadow: 0 10px 30px rgba(0,0,0,0.2);
                    margin: 20px 0;
                }}
                .info-box {{
                    background: linear-gradient(145deg, #fff3e0, #ffe0b2);
                    border-left: 5px solid #ff9800;
                    padding: 25px;
                    margin: 30px 0;
                    border-radius: 15px;
                }}
                .emoji {{ font-size: 1.2em; }}
            </style>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h1><span class="emoji">üéôÔ∏è</span> VoiceX Demo</h1>
                    <p>–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–∞</p>
                </div>
                
                <div class="audio-section">
                    <h3><span class="emoji">üé§</span> –í—Ö–æ–¥: –ì–æ—Ä–ª–æ–≤–æ–π –º–∏–∫—Ä–æ—Ñ–æ–Ω</h3>
                    <p>–°–∏–≥–Ω–∞–ª, –∑–∞—Ö–≤–∞—á–µ–Ω–Ω—ã–π —á–µ—Ä–µ–∑ –≤–∏–±—Ä–∞—Ü–∏–∏ –∫–æ–∂–∏ —à–µ–∏</p>
                    <audio controls>
                        <source src="input_throat.wav" type="audio/wav">
                        –í–∞—à –±—Ä–∞—É–∑–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ —ç–ª–µ–º–µ–Ω—Ç.
                    </audio>
                </div>
                
                <div class="audio-section">
                    <h3><span class="emoji">üîÑ</span> –í—ã—Ö–æ–¥: –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ä–µ—á—å (VoiceX)</h3>
                    <p>–†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ - –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –≥–æ–ª–æ—Å</p>
                    <audio controls>
                        <source src="converted_speech.wav" type="audio/wav">
                        –í–∞—à –±—Ä–∞—É–∑–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ —ç–ª–µ–º–µ–Ω—Ç.
                    </audio>
                </div>"""
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–µ–∫—Ü–∏—é —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Ä–µ—á—å—é, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å
        target_file = output_dir / 'target_speech.wav'
        if target_file.exists():
            html_content += """
                <div class="audio-section">
                    <h3><span class="emoji">üéØ</span> –≠—Ç–∞–ª–æ–Ω: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è —Ä–µ—á—å</h3>
                    <p>–¶–µ–ª–µ–≤–∞—è —Ä–µ—á—å –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞</p>
                    <audio controls>
                        <source src="target_speech.wav" type="audio/wav">
                        –í–∞—à –±—Ä–∞—É–∑–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ —ç–ª–µ–º–µ–Ω—Ç.
                    </audio>
                </div>"""
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        if 'mse' in result:
            html_content += f"""
                <div class="metrics">
                    <h3><span class="emoji">üìä</span> –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞</h3>
                    <div class="metric-grid">
                        <div class="metric-item">
                            <div class="metric-value">{result['mse']:.6f}</div>
                            <div>MSE</div>
                        </div>
                        <div class="metric-item">
                            <div class="metric-value">{result['mae']:.6f}</div>
                            <div>MAE</div>
                        </div>
                        <div class="metric-item">
                            <div class="metric-value">{result['cosine_similarity']:.3f}</div>
                            <div>–°—Ö–æ–∂–µ—Å—Ç—å</div>
                        </div>"""
            
            if 'snr_db' in result:
                html_content += f"""
                        <div class="metric-item">
                            <div class="metric-value">{result['snr_db']:.1f} dB</div>
                            <div>SNR</div>
                        </div>"""
            
            html_content += """
                    </div>
                </div>"""
        
        html_content += """
                <div>
                    <h3><span class="emoji">üìà</span> –í–∏–∑—É–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ</h3>
                    <img src="demo_comparison.png" alt="–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤ –∏ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º">
                </div>
                
                <div class="info-box">
                    <h3><span class="emoji">üß†</span> –ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:</h3>
                    <ol>
                        <li><strong>–ó–∞—Ö–≤–∞—Ç:</strong> –ì–æ—Ä–ª–æ–≤–æ–π –º–∏–∫—Ä–æ—Ñ–æ–Ω —É–ª–∞–≤–ª–∏–≤–∞–µ—Ç –≤–∏–±—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ –∫–æ–∂—É</li>
                        <li><strong>–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞:</strong> –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —à—É–º–∞ –∏ —É–ª—É—á—à–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞</li>
                        <li><strong>–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:</strong> Mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã, MFCC, pitch –∏ –¥—Ä—É–≥–∏–µ</li>
                        <li><strong>ML –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è:</strong> –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –≥–æ–ª–æ—Å</li>
                        <li><strong>–°–∏–Ω—Ç–µ–∑:</strong> –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –Ω–∞—Ç—É—Ä–∞–ª—å–Ω—É—é —Ä–µ—á—å</li>
                    </ol>
                    
                    <h4><span class="emoji">üìã</span> –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫:</h4>
                    <ul>
                        <li><strong>MSE/MAE:</strong> –ß–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º —Ç–æ—á–Ω–µ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ</li>
                        <li><strong>–°—Ö–æ–∂–µ—Å—Ç—å:</strong> –ß–µ–º –±–ª–∏–∂–µ –∫ 1, —Ç–µ–º –±–æ–ª—å—à–µ –ø–æ—Ö–æ–∂ –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª</li>
                        <li><strong>SNR:</strong> –ß–µ–º –≤—ã—à–µ, —Ç–µ–º –ª—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–∞</li>
                    </ul>
                </div>
                
                <div style="text-align: center; margin-top: 40px; color: #666;">
                    <p><em>VoiceX - –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –≥–æ–ª–æ—Å–∞ —á–µ—Ä–µ–∑ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ</em></p>
                </div>
            </div>
        </body>
        </html>
        """
        
        html_path = output_dir / 'demo.html'
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"üåê HTML –¥–µ–º–æ —Å–æ–∑–¥–∞–Ω–æ: {html_path}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    parser = argparse.ArgumentParser(description='–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ VoiceX')
    parser.add_argument('--model_path', type=str, required=True,
                       help='–ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (.h5 –∏–ª–∏ .tflite)')
    parser.add_argument('--config_path', type=str, required=True,
                       help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏')
    parser.add_argument('--scaler_path', type=str, required=True,
                       help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å–∫–µ–π–ª–µ—Ä–∞')
    parser.add_argument('--data_path', type=str,
                       help='–ü—É—Ç—å –∫ —Ç–µ—Å—Ç–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º')
    parser.add_argument('--throat_file', type=str,
                       help='–§–∞–π–ª –≥–æ—Ä–ª–æ–≤–æ–≥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –¥–ª—è –µ–¥–∏–Ω–∏—á–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞')
    parser.add_argument('--speech_file', type=str,
                       help='–§–∞–π–ª –æ–±—ã—á–Ω–æ–π —Ä–µ—á–∏ –¥–ª—è –µ–¥–∏–Ω–∏—á–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞')
    parser.add_argument('--output_dir', type=str, default='./test_results',
                       help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤')
    parser.add_argument('--num_samples', type=int, default=50,
                       help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è')
    parser.add_argument('--demo', action='store_true',
                       help='–°–æ–∑–¥–∞—Ç—å –¥–µ–º–æ-—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ')
    parser.add_argument('--test_dataset', action='store_true',
                       help='–¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ –≤—Å–µ–º –¥–∞—Ç–∞—Å–µ—Ç–µ')
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    os.makedirs(args.output_dir, exist_ok=True)
    
    print("üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ VoiceX")
    print("=" * 50)
    
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–µ—Ä–∞
        tester = VoiceXModelTester(
            model_path=args.model_path,
            config_path=args.config_path,
            scaler_path=args.scaler_path
        )
        
        # –ï–¥–∏–Ω–∏—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        if args.throat_file:
            print("üîÑ –ï–¥–∏–Ω–∏—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ...")
            result = tester.test_single_sample(args.throat_file, args.speech_file)
            
            if result:
                print("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç –µ–¥–∏–Ω–∏—á–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞:")
                print(f"   –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {result['input_file']}")
                print(f"   –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {result.get('output_file', '–ù–µ —Å–æ–∑–¥–∞–Ω')}")
                print(f"   –£—Å–ø–µ—Ö –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {result['conversion_success']}")
                print(f"   –†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {result.get('throat_features_shape', 'N/A')}")
                print(f"   –†–∞–∑–º–µ—Ä –≤—ã—Ö–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {result.get('predicted_features_shape', 'N/A')}")
                
                if 'mse' in result:
                    print(f"   MSE: {result['mse']:.6f}")
                    print(f"   MAE: {result['mae']:.6f}")
                    print(f"   –ö–æ—Å–∏–Ω—É—Å–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å: {result['cosine_similarity']:.3f}")
                    if 'snr_db' in result:
                        print(f"   SNR: {result['snr_db']:.2f} dB")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ
        if args.demo and args.throat_file:
            print("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ-—Å—Ä–∞–≤–Ω–µ–Ω–∏—è...")
            demo_result = tester.create_demo_comparison(
                throat_file=args.throat_file,
                speech_file=args.speech_file,
                output_dir=args.output_dir
            )
            
            if demo_result:
                print("‚úÖ –î–µ–º–æ-—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
                print(f"   HTML –¥–µ–º–æ: {args.output_dir}/demo.html")
                print(f"   –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è: {demo_result['comparison_image']}")
        
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
        if args.test_dataset and args.data_path:
            print("üîÑ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ...")
            results = tester.test_dataset(
                data_path=args.data_path,
                output_dir=args.output_dir,
                num_samples=args.num_samples
            )
            
            if results:
                print("‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
                print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {args.output_dir}")
                print(f"   HTML –æ—Ç—á–µ—Ç: {args.output_dir}/test_report.html")
        
        print("=" * 50)
        print("üéâ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        print(f"üìÅ –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {args.output_dir}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    import sys
    sys.exit(main())